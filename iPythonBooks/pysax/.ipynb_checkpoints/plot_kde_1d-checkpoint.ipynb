{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Simple 1D Kernel Density Estimation\n",
    "\n",
    "This example uses the :class:`sklearn.neighbors.KernelDensity` class to\n",
    "demonstrate the principles of Kernel Density Estimation in one dimension.\n",
    "\n",
    "The first plot shows one of the problems with using histograms to visualize\n",
    "the density of points in 1D. Intuitively, a histogram can be thought of as a\n",
    "scheme in which a unit \"block\" is stacked above each point on a regular grid.\n",
    "As the top two panels show, however, the choice of gridding for these blocks\n",
    "can lead to wildly divergent ideas about the underlying shape of the density\n",
    "distribution.  If we instead center each block on the point it represents, we\n",
    "get the estimate shown in the bottom left panel.  This is a kernel density\n",
    "estimation with a \"top hat\" kernel.  This idea can be generalized to other\n",
    "kernel shapes: the bottom-right panel of the first figure shows a Gaussian\n",
    "kernel density estimate over the same distribution.\n",
    "\n",
    "Scikit-learn implements efficient kernel density estimation using either\n",
    "a Ball Tree or KD Tree structure, through the\n",
    ":class:`sklearn.neighbors.KernelDensity` estimator.  The available kernels\n",
    "are shown in the second figure of this example.\n",
    "\n",
    "The third figure compares kernel density estimates for a distribution of 100\n",
    "samples in 1 dimension.  Though this example uses 1D distributions, kernel\n",
    "density estimation is easily and efficiently extensible to higher dimensions\n",
    "as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Author: Jake Vanderplas <jakevdp@cs.washington.edu>\n",
    "#\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Plot the progression of histograms to kernels\n",
    "np.random.seed(1)\n",
    "N = 20\n",
    "X = np.concatenate((np.random.normal(0, 1, 0.3 * N),\n",
    "                    np.random.normal(5, 1, 0.7 * N)))[:, np.newaxis]\n",
    "X_plot = np.linspace(-5, 10, 1000)[:, np.newaxis]\n",
    "bins = np.linspace(-5, 10, 10)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "# histogram 1\n",
    "ax[0, 0].hist(X[:, 0], bins=bins, fc='#AAAAFF', normed=True)\n",
    "ax[0, 0].text(-3.5, 0.31, \"Histogram\")\n",
    "\n",
    "# histogram 2\n",
    "ax[0, 1].hist(X[:, 0], bins=bins + 0.75, fc='#AAAAFF', normed=True)\n",
    "ax[0, 1].text(-3.5, 0.31, \"Histogram, bins shifted\")\n",
    "\n",
    "# tophat KDE\n",
    "kde = KernelDensity(kernel='tophat', bandwidth=0.75).fit(X)\n",
    "log_dens = kde.score_samples(X_plot)\n",
    "ax[1, 0].fill(X_plot[:, 0], np.exp(log_dens), fc='#AAAAFF')\n",
    "ax[1, 0].text(-3.5, 0.31, \"Tophat Kernel Density\")\n",
    "\n",
    "# Gaussian KDE\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.75).fit(X)\n",
    "log_dens = kde.score_samples(X_plot)\n",
    "ax[1, 1].fill(X_plot[:, 0], np.exp(log_dens), fc='#AAAAFF')\n",
    "ax[1, 1].text(-3.5, 0.31, \"Gaussian Kernel Density\")\n",
    "\n",
    "for axi in ax.ravel():\n",
    "    axi.plot(X[:, 0], np.zeros(X.shape[0]) - 0.01, '+k')\n",
    "    axi.set_xlim(-4, 9)\n",
    "    axi.set_ylim(-0.02, 0.34)\n",
    "\n",
    "for axi in ax[:, 0]:\n",
    "    axi.set_ylabel('Normalized Density')\n",
    "\n",
    "for axi in ax[1, :]:\n",
    "    axi.set_xlabel('x')\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Plot all available kernels\n",
    "X_plot = np.linspace(-6, 6, 1000)[:, None]\n",
    "X_src = np.zeros((1, 1))\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, sharex=True, sharey=True)\n",
    "fig.subplots_adjust(left=0.05, right=0.95, hspace=0.05, wspace=0.05)\n",
    "\n",
    "\n",
    "def format_func(x, loc):\n",
    "    if x == 0:\n",
    "        return '0'\n",
    "    elif x == 1:\n",
    "        return 'h'\n",
    "    elif x == -1:\n",
    "        return '-h'\n",
    "    else:\n",
    "        return '%ih' % x\n",
    "\n",
    "for i, kernel in enumerate(['gaussian', 'tophat', 'epanechnikov',\n",
    "                            'exponential', 'linear', 'cosine']):\n",
    "    axi = ax.ravel()[i]\n",
    "    log_dens = KernelDensity(kernel=kernel).fit(X_src).score_samples(X_plot)\n",
    "    axi.fill(X_plot[:, 0], np.exp(log_dens), '-k', fc='#AAAAFF')\n",
    "    axi.text(-2.6, 0.95, kernel)\n",
    "\n",
    "    axi.xaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "    axi.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "    axi.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "    axi.set_ylim(0, 1.05)\n",
    "    axi.set_xlim(-2.9, 2.9)\n",
    "\n",
    "ax[0, 1].set_title('Available Kernels')\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Plot a 1D density example\n",
    "N = 100\n",
    "np.random.seed(1)\n",
    "X = np.concatenate((np.random.normal(0, 1, 0.3 * N),\n",
    "                    np.random.normal(5, 1, 0.7 * N)))[:, np.newaxis]\n",
    "\n",
    "X_plot = np.linspace(-5, 10, 1000)[:, np.newaxis]\n",
    "\n",
    "true_dens = (0.3 * norm(0, 1).pdf(X_plot[:, 0])\n",
    "             + 0.7 * norm(5, 1).pdf(X_plot[:, 0]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.fill(X_plot[:, 0], true_dens, fc='black', alpha=0.2,\n",
    "        label='input distribution')\n",
    "\n",
    "for kernel in ['gaussian', 'tophat', 'epanechnikov']:\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=0.5).fit(X)\n",
    "    log_dens = kde.score_samples(X_plot)\n",
    "    ax.plot(X_plot[:, 0], np.exp(log_dens), '-',\n",
    "            label=\"kernel = '{0}'\".format(kernel))\n",
    "\n",
    "ax.text(6, 0.38, \"N={0} points\".format(N))\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "ax.plot(X[:, 0], -0.005 - 0.01 * np.random.random(X.shape[0]), '+k')\n",
    "\n",
    "ax.set_xlim(-4, 9)\n",
    "ax.set_ylim(-0.02, 0.4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
